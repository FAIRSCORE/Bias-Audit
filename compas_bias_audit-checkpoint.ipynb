{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c869a20",
   "metadata": {},
   "source": [
    "# COMPAS Bias Audit Notebook\n",
    "\n",
    "This notebook performs a fairness and bias audit on the COMPAS two-year recidivism dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn aif360 fairlearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dc70a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "\n",
    "from fairlearn.metrics import MetricFrame, selection_rate, true_positive_rate, false_positive_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5373a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace with your actual path to compas-scores-two-years.csv\n",
    "df = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cceb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define features and labels\n",
    "features = [\"sex\", \"age\", \"juv_fel_count\", \"juv_misd_count\", \"priors_count\", \"c_charge_degree\"]\n",
    "X = pd.get_dummies(df[features], drop_first=True)\n",
    "y = df[\"two_year_recid\"].astype(int)\n",
    "protected_attr = df[\"race\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079be75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X)\n",
    "y_prob = clf.predict_proba(X)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y, y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aif_data = BinaryLabelDataset(\n",
    "    favorable_label=0,\n",
    "    unfavorable_label=1,\n",
    "    df=pd.concat([X, y, protected_attr], axis=1),\n",
    "    label_names=[\"two_year_recid\"],\n",
    "    protected_attribute_names=[\"race\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d1deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mf = MetricFrame(\n",
    "    metrics={\n",
    "        \"accuracy\": accuracy_score,\n",
    "        \"selection_rate\": selection_rate,\n",
    "        \"TPR\": true_positive_rate,\n",
    "        \"FPR\": false_positive_rate\n",
    "    },\n",
    "    y_true=y,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=protected_attr\n",
    ")\n",
    "\n",
    "print(mf.by_group)\n",
    "mf.by_group.plot(kind=\"bar\", subplots=True, layout=(2,2), figsize=(10,6), legend=False)\n",
    "plt.suptitle(\"Baseline Fairness Metrics by Race\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18cec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RW = Reweighing(unprivileged_groups=[{\"race\": \"African-American\"}],\n",
    "                privileged_groups=[{\"race\": \"Caucasian\"}])\n",
    "aif_rw = RW.fit_transform(aif_data)\n",
    "\n",
    "clf_rw = LogisticRegression(max_iter=1000)\n",
    "clf_rw.fit(X, y, sample_weight=aif_rw.instance_weights)\n",
    "y_pred_rw = clf_rw.predict(X)\n",
    "\n",
    "print(\"Post-Reweighing Accuracy:\", accuracy_score(y, y_pred_rw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa38bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eq_odds = EqOddsPostprocessing(\n",
    "    unprivileged_groups=[{\"race\": \"African-American\"}],\n",
    "    privileged_groups=[{\"race\": \"Caucasian\"}]\n",
    ")\n",
    "eq_odds = eq_odds.fit(aif_data, aif_data)\n",
    "aif_eq = eq_odds.predict(aif_data)\n",
    "\n",
    "cm = ClassificationMetric(aif_data, aif_eq,\n",
    "    unprivileged_groups=[{\"race\": \"African-American\"}],\n",
    "    privileged_groups=[{\"race\": \"Caucasian\"}]\n",
    ")\n",
    "\n",
    "print(\"Equal Opportunity Difference:\", cm.equal_opportunity_difference())\n",
    "print(\"Average Odds Difference:\", cm.average_odds_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858cfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Recommendations:\")\n",
    "print(\"- Collect more balanced demographic data\")\n",
    "print(\"- Perform intersectional analysis (race x gender)\")\n",
    "print(\"- Use interpretable models with fairness constraints\")\n",
    "print(\"- Document fairness metrics with Model Cards\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}